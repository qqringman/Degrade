"""
JIRA Degrade åˆ†æç®¡ç†æ¨¡çµ„ - è¶…å¿«é€Ÿç‰ˆæœ¬
ä½¿ç”¨ä¸¦è¡Œè™•ç†å’Œå„ªåŒ–çš„ batch size
ä¿®æ”¹ï¼š
- Degrade issues ä½¿ç”¨ created æ¬„ä½
- Resolved issues ä½¿ç”¨ resolutiondate æ¬„ä½
"""
import os
import requests
import re
from datetime import datetime
from typing import List, Dict, Any
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

class JiraDegradeManagerFast:
    """JIRA Degrade çµ±è¨ˆç®¡ç†é¡åˆ¥ - å„ªåŒ–ç‰ˆæœ¬"""
    
    def __init__(self, site, user, password, token=None):
        self.site = site
        self.user = user
        self.password = password
        self.token = token
        self.base_url = f"https://{site}"
        
        # è¨­å®šèªè­‰æ–¹å¼
        if token:
            self.auth = None
            self.headers = {
                "Accept": "application/json",
                "Authorization": f"Bearer {token}"
            }
        else:
            self.auth = (user, password)
            self.headers = {"Accept": "application/json"}
    
    def _make_request(self, url: str, method: str = 'GET', **kwargs) -> requests.Response:
        """çµ±ä¸€çš„è«‹æ±‚æ–¹æ³•"""
        headers = kwargs.get('headers', {})
        headers.update(self.headers)
        kwargs['headers'] = headers
        
        if not self.token and self.auth:
            kwargs['auth'] = self.auth
        
        if method.upper() == 'GET':
            return requests.get(url, **kwargs)
        elif method.upper() == 'POST':
            return requests.post(url, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„ HTTP æ–¹æ³•: {method}")
    
    def get_filter_issues_fast(self, filter_id: str, max_results: int = None) -> List[Dict[str, Any]]:
        """
        å¿«é€Ÿå–å¾—æŒ‡å®š filter çš„æ‰€æœ‰ issues
        ä½¿ç”¨æ›´å¤§çš„ batch size å’Œå„ªåŒ–çš„æ¬„ä½
        
        Args:
            filter_id: JIRA filter ID
            max_results: æœ€å¤šå–å¾—å¹¾ç­†è³‡æ–™ (None = ç„¡ä¸Šé™ï¼Œè¼‰å…¥å…¨éƒ¨)
            
        Returns:
            issues åˆ—è¡¨
        """
        all_issues = []
        start_at = 0
        batch_size = 500  # æ¯æ¬¡æŠ“ 500 ç­†
        
        start_time = time.time()
        
        try:
            while True:  # æ”¹ç‚ºç„¡é™è¿´åœˆï¼Œç›´åˆ°æ²’æœ‰æ›´å¤šè³‡æ–™
                url = f"{self.base_url}/rest/api/2/search"
                params = {
                    'jql': f'filter={filter_id}',
                    'startAt': start_at,
                    'maxResults': batch_size,
                    # æŠ“å–éœ€è¦çš„æ¬„ä½
                    # created: ç”¨æ–¼ degrade issues
                    # resolutiondate: ç”¨æ–¼ resolved issues
                    # updated: å‚™ç”¨
                    'fields': 'key,assignee,created,resolutiondate,updated'
                }
                
                response = self._make_request(url, params=params, timeout=60)
                
                if response.status_code != 200:
                    print(f"  âŒ Filter {filter_id} å¤±æ•—: HTTP {response.status_code}")
                    break
                
                data = response.json()
                issues = data.get('issues', [])
                
                if not issues:
                    break
                
                all_issues.extend(issues)
                
                # æª¢æŸ¥æ˜¯å¦é‚„æœ‰æ›´å¤šè³‡æ–™
                total = data.get('total', 0)
                print(f"  ğŸ“Š Filter {filter_id}: å·²è¼‰å…¥ {len(all_issues)}/{total} ç­†")
                
                # å¦‚æœæœ‰è¨­å®šä¸Šé™ä¸”å·²é”åˆ°ï¼Œåœæ­¢
                if max_results and len(all_issues) >= max_results:
                    break
                
                # å¦‚æœå·²ç¶“è¼‰å…¥å…¨éƒ¨è³‡æ–™ï¼Œåœæ­¢
                if start_at + batch_size >= total:
                    break
                
                start_at += batch_size
            
            elapsed = time.time() - start_time
            print(f"  âœ“ Filter {filter_id} å®Œæˆ: {len(all_issues)} ç­† ({elapsed:.1f}ç§’)")
            
            # å¦‚æœæœ‰ä¸Šé™ï¼Œæˆªæ–·çµæœï¼›å¦å‰‡å›å‚³å…¨éƒ¨
            if max_results:
                return all_issues[:max_results]
            else:
                return all_issues
            
        except Exception as e:
            print(f"  âŒ Filter {filter_id} å¤±æ•—: {str(e)}")
            return []
    
    def get_week_number(self, date_str: str) -> str:
        """
        å°‡æ—¥æœŸè½‰æ›ç‚ºé€±æ¬¡ (YYYY-Wxx)
        """
        try:
            if 'T' in date_str:
                date_str = date_str.split('T')[0]
            
            date_obj = datetime.strptime(date_str[:10], '%Y-%m-%d')
            iso_calendar = date_obj.isocalendar()
            return f"{iso_calendar[0]}-W{iso_calendar[1]:02d}"
        except Exception as e:
            return "Unknown"
    
    def analyze_by_week(self, issues: List[Dict[str, Any]], date_field: str = 'updated') -> Dict[str, Any]:
        """
        æŒ‰é€±çµ±è¨ˆ issues - å„ªåŒ–ç‰ˆæœ¬
        æ”¯æ´ä¸åŒçš„æ—¥æœŸæ¬„ä½ï¼šcreated, resolutiondate, updated
        """
        weekly_stats = defaultdict(lambda: {
            'count': 0,
            'issues': [],
            'assignees': defaultdict(int)
        })
        
        for issue in issues:
            fields = issue.get('fields', {})
            date_str = fields.get(date_field)
            
            if not date_str:
                continue
            
            week = self.get_week_number(date_str)
            weekly_stats[week]['count'] += 1
            weekly_stats[week]['issues'].append(issue.get('key'))
            
            assignee = fields.get('assignee')
            if assignee:
                assignee_name = assignee.get('displayName', 'Unassigned')
            else:
                assignee_name = 'Unassigned'
            
            weekly_stats[week]['assignees'][assignee_name] += 1
        
        return dict(weekly_stats)
    
    def get_assignee_distribution(self, issues: List[Dict[str, Any]]) -> Dict[str, int]:
        """
        çµ±è¨ˆ assignee åˆ†å¸ƒ - å„ªåŒ–ç‰ˆæœ¬
        """
        assignee_stats = defaultdict(int)
        
        for issue in issues:
            fields = issue.get('fields', {})
            assignee = fields.get('assignee')
            
            if assignee:
                assignee_name = assignee.get('displayName', 'Unassigned')
            else:
                assignee_name = 'Unassigned'
            
            assignee_stats[assignee_name] += 1
        
        return dict(assignee_stats)


def load_all_filters_parallel(jira_configs, filters):
    """
    ä¸¦è¡Œè¼‰å…¥æ‰€æœ‰ filters - é€™æ˜¯é€Ÿåº¦æå‡çš„é—œéµï¼
    
    Args:
        jira_configs: JIRA é€£ç·šè¨­å®š
        filters: Filter IDs
        
    Returns:
        æ‰€æœ‰è³‡æ–™
    """
    print("=" * 70)
    print("ğŸš€ é–‹å§‹ä¸¦è¡Œè¼‰å…¥ JIRA è³‡æ–™...")
    start_time = time.time()
    
    # å»ºç«‹ JIRA managers
    internal_jira = JiraDegradeManagerFast(
        site=jira_configs['internal']['site'],
        user=jira_configs['internal']['user'],
        password=jira_configs['internal']['password'],
        token=jira_configs['internal']['token']
    )
    
    vendor_jira = JiraDegradeManagerFast(
        site=jira_configs['vendor']['site'],
        user=jira_configs['vendor']['user'],
        password=jira_configs['vendor']['password'],
        token=jira_configs['vendor']['token']
    )
    
    # å®šç¾©è¦åŸ·è¡Œçš„ä»»å‹™
    tasks = [
        ('internal_degrade', internal_jira, filters['degrade']['internal']),
        ('vendor_degrade', vendor_jira, filters['degrade']['vendor']),
        ('internal_resolved', internal_jira, filters['resolved']['internal']),
        ('vendor_resolved', vendor_jira, filters['resolved']['vendor'])
    ]
    
    # ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡ŒåŸ·è¡Œ
    results = {}
    with ThreadPoolExecutor(max_workers=4) as executor:
        # æäº¤æ‰€æœ‰ä»»å‹™
        future_to_task = {
            executor.submit(jira.get_filter_issues_fast, filter_id): task_name
            for task_name, jira, filter_id in tasks
        }
        
        # æ”¶é›†çµæœ
        for future in as_completed(future_to_task):
            task_name = future_to_task[future]
            try:
                results[task_name] = future.result()
            except Exception as e:
                print(f"  âŒ {task_name} å¤±æ•—: {e}")
                results[task_name] = []
    
    # æ¨™è¨˜ä¾†æºä¸¦åˆä½µ
    for issue in results.get('internal_degrade', []):
        issue['_source'] = 'internal'
    for issue in results.get('vendor_degrade', []):
        issue['_source'] = 'vendor'
    for issue in results.get('internal_resolved', []):
        issue['_source'] = 'internal'
    for issue in results.get('vendor_resolved', []):
        issue['_source'] = 'vendor'
    
    all_degrade = results.get('internal_degrade', []) + results.get('vendor_degrade', [])
    all_resolved = results.get('internal_resolved', []) + results.get('vendor_resolved', [])
    
    print("\nğŸ“Š çµ±è¨ˆåˆ†æä¸­...")
    # ä½¿ç”¨ä»»ä¸€ manager åšçµ±è¨ˆ
    # Degrade ä½¿ç”¨ createdï¼ŒResolved ä½¿ç”¨ resolutiondate
    degrade_weekly = internal_jira.analyze_by_week(all_degrade, date_field='created')
    resolved_weekly = internal_jira.analyze_by_week(all_resolved, date_field='resolutiondate')
    degrade_assignees = internal_jira.get_assignee_distribution(all_degrade)
    resolved_assignees = internal_jira.get_assignee_distribution(all_resolved)
    
    total_time = time.time() - start_time
    print(f"\nâœ… è³‡æ–™è¼‰å…¥å®Œæˆï¼")
    print(f"  â±  ç¸½è€—æ™‚: {total_time:.1f} ç§’")
    print(f"  ğŸ“ˆ Degrade: {len(all_degrade)} ç­† (ä½¿ç”¨ created æ—¥æœŸ)")
    print(f"  ğŸ“ˆ Resolved: {len(all_resolved)} ç­† (ä½¿ç”¨ resolutiondate)")
    print(f"  ğŸš€ å¹³å‡æ¯ç§’è™•ç†: {(len(all_degrade) + len(all_resolved)) / total_time:.0f} ç­†")
    print("=" * 70)
    
    return {
        'degrade': {
            'total': len(all_degrade),
            'weekly': degrade_weekly,
            'assignees': degrade_assignees,
            'issues': all_degrade
        },
        'resolved': {
            'total': len(all_resolved),
            'weekly': resolved_weekly,
            'assignees': resolved_assignees,
            'issues': all_resolved
        },
        'metadata': {
            'load_time': total_time,
            'timestamp': datetime.now().isoformat()
        }
    }